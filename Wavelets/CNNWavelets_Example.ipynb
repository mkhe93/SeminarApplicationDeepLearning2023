{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Allows imports from modules in the project directory\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIRECTORY = Path(os.path.abspath('')).resolve()\n",
    "MODULE_DIRECTORY = CURRENT_DIRECTORY.parent\n",
    "PROJECT_DIRECTORY = MODULE_DIRECTORY.parents[1]\n",
    "sys.path.extend([str(MODULE_DIRECTORY)])\n",
    "\n",
    "print(f'Python {sys.version} on {sys.platform}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utilities"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameter\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "EPOCHS = 5\n",
    "\n",
    "wavelet_name = 'gaus5'\n",
    "scales = 20"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Load wavelet data\n",
    "train_path = CURRENT_DIRECTORY / f'{wavelet_name}_{scales}/train.npz'\n",
    "test_path = CURRENT_DIRECTORY / f'{wavelet_name}_{scales}/test.npz'\n",
    "\n",
    "train = np.load(train_path)\n",
    "test = np.load(test_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the train and test data\n",
    "train_data = train['data']\n",
    "train_labels = train['labels']\n",
    "\n",
    "test_data = test['data']\n",
    "test_labels = test['labels']"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Data generator allows to transform each batch in training and evaluate the test set after each epoche\n",
    "class DataGenerator(utilities.BaseDataGenerator):\n",
    "    # There is no transformation needed, but it is still convenient to use a generator here\n",
    "    # since using a tensorflow dataset would use more memory than is available on my machine\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize data generators\n",
    "train_generator = DataGenerator(train_data, train_labels, batch_size=BATCH_SIZE)\n",
    "test_generator = DataGenerator(test_data, test_labels, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(20, 500, 6)),\n",
    "\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D((1, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(64, 4, activation='relu'),\n",
    "    keras.layers.MaxPooling2D((1, 3)),\n",
    "\n",
    "    keras.layers.Conv2D(72, 5, activation='relu'),\n",
    "    keras.layers.MaxPooling2D((1, 3)),\n",
    "\n",
    "    keras.layers.Conv2D(80, 6, activation='relu'),\n",
    "    keras.layers.MaxPooling2D((1, 3)),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.7),\n",
    "    keras.layers.Dense(4, activation='softmax'),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model on the training set and evaluate the test set on the end of each epoche\n",
    "history = model.fit(train_generator, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
