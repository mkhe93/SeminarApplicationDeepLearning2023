# Generating Synthetic Data Using GANs

## Deep-Convolutional-GAN

This model typically consists of a generator and a discriminator. Both the generator and discriminator are constructed using 1D convolutional layers, which have already proven effective in classification tasks.

The code and structure are implemented based on TensorFlow's tutorial [Deep Convolutional Generative Adversarial Network](https://www.tensorflow.org/tutorials/generative/dcgan).

The size and type of layers have been adapted from the example of MNIST image generation to time-series generation.

The best model, along with some generated data, is available in the `models/dcgan` directory and can be loaded as an example in `load_gan.ipynb`.

## Time-GAN

The concept originates from a paper by [Jinsung Yoon et al. (2019)](https://proceedings.neurips.cc/paper_files/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf), which presents a promising approach for generating time-series data.

This model includes, in addition to the classic components of a generator and discriminator, two additional components: _Embedding_ and _Recovery_. These components work together as an autoencoder to create a lower-dimensional latent space for the generator. In addition to the adversarial process involving the discriminator and generator, a reconstruction loss and supervised loss are introduced, which further improve the quality of the data generated by the generator.

TimeGAN is also available as a framework provided by the authors via [ydata-synthetic](https://github.com/ydataai/ydata-synthetic) and can be installed with:

        pip install ydata-synthetic


The tutorial for this framework can be found [here in Google Colab](https://colab.research.google.com/github/ydataai/ydata-synthetic/blob/master/examples/timeseries/TimeGAN_Synthetic_stock_data.ipynb). However, installation issues arose, so code from a project and repository published by Stefan Jansen, [Generative Adversarial Nets for Synthetic Time Series Data](https://stefan-jansen.github.io/machine-learning-for-trading/21_gans_for_synthetic_time_series/), was used instead. A notebook, [TimeGAN_TF2](https://stefan-jansen.github.io/machine-learning-for-trading/21_gans_for_synthetic_time_series/02_TimeGAN_TF2.ipynb) (__WARNING: Direct download link!__), which implements the TimeGAN architecture, is referenced below.

## Limitations

Both models were trained on highly compressed data. Due to the additional networks (particularly in TimeGAN), significant computation times are expected. As a result, the DCGAN was tested with a sampling length of only 128, and the TimeGAN with a sampling length of 24. Additionally, only data from the underrepresented label class `= 0` was used, specifically the $a_x$ recordings. The aim was to present a functional network capable of reproducing a time series, allowing future work to leverage more computational resources to explore larger samples.

## Approach

The DCGAN was adapted from a 2D case to a 1D case for time-series data, and the TimeGAN was trained only on the small dataset. A brief evaluation involved plotting the synthetic data alongside the existing data and calculating the average across all time points in the subset, resulting in a curve of average values. This reflects the average accuracy of the generated synthetic data. The corresponding images can be found in the `models/dcgan` and `models/timegan` directories.

## Results

Based on the described qualitative quality assessment, both GANs produced sufficiently good results for the initial test. As expected, the TimeGAN generated smoother and, on average, more accurate samples than the DCGAN. This encourages further investigation with additional computational resources and potential parameter tuning. Since these networks consist of multiple models, their full representation is omitted in this notebook. The models are loaded in their respective notebooks. For the DCGAN, only the generator is needed for sample generation, while the TimeGAN requires the network comprising the generator, supervisor, a

### _Model: DCGAN (Generator)_

| Layer (type)   |      Output Shape      |  Param # |
|----------|-------------|------:|
| Dense |  (None, 4096) | 4194304 |
| BatchNormalization |  (None, 4096) | 16384 |
| LeakyReLU |  (None, 4096) | 0 |
| Reshape |  (None, 62, 192) | 0 |
| Conv1DTranspose |  (None, 32, 256) | 163840 |
| BatchNormalization |  (None, 32, 256) | 1024 |
| LeakyReLU |  (None, 32, 256) | 0 |
| Conv1DTranspose |  (None, 64, 128) | 163840 |
| BatchNormalization |  (None, 64, 128) | 512 |
| LeakyReLU |  (None, 64, 256) | 0 |
| Conv1DTranspose |  (None, 128, 1) |  640|
Total params: 4.540.544
Trainable params: 4.531.584
Non-trainable params: 0

### _Model: TimeGAN_

| Layer (type)   |      Output Shape      |  Param # |
|----------|-------------|------:|
| InputLayer |  (None, 24, 1) | 0 |
| Generator |  (None, 24, 128) | 346240 |
| Supervisor |  (None, 24, 128) | 279680 |
| Recovery |  (None, 24, 1) | 394881 |
Total params: 1.020.801
Trainable params: 1.020.801
Non-trainable params: 0

The training process and the full architecture of both models can be reviewed in `DCGAN.ipynb` and `TimeGAN.ipynb`. For TimeGAN, additional theoretical knowledge may be required to fully understand its functionality. This is well explained in the final report or from page 3, chapter 4, of [Jinsung Yoon et al. (2019)](https://proceedings.neurips.cc/paper_files/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf). In particular, the variable notations are clarified there. In summary:

- **$X$**: Real data  
- **$Z$**: Randomly generated samples (noise)  
- **$H$**: Latent space generated by the embedder ($H = Embedder(X)$)  
- **$\tilde{X}$**: Reconstructed data generated by the recovery network from the latent space ($\tilde{X} = Recovery(H)$)  
- **$\hat{E}$**: Data generated by the generator from $Z$  
- **$\hat{H}$**: Data generated by the supervisor from $\hat{E}$  
- **$Y_{fake}$**: Samples from $\hat{H}$ evaluated by the discriminator  
- **$Y_{{fake}_e}$**: Samples from $\hat{E}$ evaluated by the discriminator  

### Relationships Between Components

- The **_Embedder_** and **_Recovery_** together form the **Autoencoder**:  
  $Autoencoder(X) = Recovery(Embedder(X))$  

- The **_Generator_**, **_Supervisor_**, and **_Discriminator_** together form the **Adversarial Supervised Network** for calculating the adversarial supervised loss:  
  $AdversarialSupervised(Z) = Discriminator(Supervisor(Generator(Z)))$  

- The **_Generator_** and **_Discriminator_** together form the **Adversarial Embedding Network**:  
  $AdversarialEmbedding(Z) = Discriminator(Generator(Z))$  

- The **_Recovery_**, **_Generator_**, and **_Supervisor_** together form the network for generating synthetic data:  
  $SyntheticData(Z) = Recovery(Supervisor(Generator(Z)))$  

  
  ## Approaches to Measure Quality

Better approaches to quantitatively measure quality are provided by Stefan Jansen in his article [Evaluating the quality of synthetic time-series data](https://stefan-jansen.github.io/machine-learning-for-trading/21_gans_for_synthetic_time_series/) and by [Brophy, Eoin et al. (2021)](https://arxiv.org/pdf/2107.11098.pdf) on pages 16-17. 

In summary, classic statistical tests as well as clustering methods can provide insights into the distribution of synthetic data compared to real data. These methods can also address the quality criteria recommended by Jansen: diversity, distinguishability, and usefulness.